{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide": true
   },
   "source": [
    "# Lab 7 - Logistic Regression, ROCs and imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "import seaborn.apionly as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'd like to simply notice that our data set is very highly asymmetric, with positives, or people who churned, only making up 14-15% of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gssdata=pd.read_csv(\"gssdata4.csv\")\n",
    "gssdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorhealth = np.where(gssdata['health'] == 'poor',1,0)\n",
    "excellenthealth = np.where(gssdata['health'] == 'excellent',1,0)\n",
    "fairhealth = np.where(gssdata['health'] == 'fair',1,0)\n",
    "gssdata['poorhealth'] = poorhealth\n",
    "gssdata['fairhealth'] = fairhealth\n",
    "gssdata['excellenthealth'] = excellenthealth\n",
    "100*gssdata.poorhealth.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This means that a classifier which predicts EVERY respondent to not be in excellent health will have an accuracy rate of 80-81%. \n",
    "\n",
    "But is accuracy the correct metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a logistic model ignoring missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by fitting a logistic regression model to predict poor health based on all the other predictors in the model.  Be sure to regularize (with CV) to make sure we are not overfitting to the data.\n",
    "\n",
    "First we need to do a small amount of data clean-up (ignoring missingness for now in income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating dummies two ways\n",
    "gssdata['female'] = 1*(gssdata['sex'] ==  'female')\n",
    "dummy_vars = pd.get_dummies(gssdata[['sexornt','partyid','race']])\n",
    "gssdata = gssdata.join(dummy_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gssdata.shape)\n",
    "gssdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gssdata_full = gssdata.dropna(how = 'any')\n",
    "print(gssdata_full.shape)\n",
    "gssdata_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "itrain, itest = train_test_split(range(gssdata_full.shape[0]), train_size=0.50)\n",
    "#gsstemp = gssdata_full.drop(['health','fairhealth','goodhealth','excellenthealth','sex','sexornt','partyid','race'],axis=1)\n",
    "gsstemp = gssdata_full[['age','educ','female','partyid_dem','partyid_rep','income']]\n",
    "X_train = gsstemp.iloc[itrain, :]\n",
    "X_test = gsstemp.iloc[itest, :]\n",
    "y_train = gssdata_full['poorhealth'].iloc[itrain]\n",
    "y_test = gssdata_full['poorhealth'].iloc[itest]\n",
    "\n",
    "y_train.shape, X_train.shape, y_test.shape, X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsstemp.head()\n",
    "100*gssdata_full.poorhealth.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(C=1000000)\n",
    "logit.fit(X_train, y_train) \n",
    "print(logit.score(X_test,y_test))\n",
    "logit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember the Confusion matrix? We reproduce it here for convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the samples that are +ive and the classifier predicts as +ive are called True Positives (TP)\n",
    "- the samples that are -ive and the classifier predicts (wrongly) as +ive are called False Positives (FP)\n",
    "- the samples that are -ive and the classifier predicts as -ive are called True Negatives (TN)\n",
    "- the samples that are +ive and the classifier predicts as -ive are called False Negatives (FN)\n",
    "\n",
    "A classifier produces a confusion matrix which looks like this:\n",
    "\n",
    "![confusionmatrix](./confusionmatrix_360.png)\n",
    "\n",
    "\n",
    "IMPORTANT NOTE: In sklearn, to obtain the confusion matrix in the form above, always have the observed `y` first, i.e.: use as `confusion_matrix(y_true, y_pred)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,logit.predict(X_test)))\n",
    "yhats = logit.predict_proba(X_train)\n",
    "plt.hist(yhats[:,1])\n",
    "#print(confusion_matrix(y_test,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually making confusion table from a different threshold\n",
    "def t_repredict(est, t, xtest):\n",
    "    probs = est.predict_proba(xtest)\n",
    "    p0 = probs[:,0]\n",
    "    p1 = probs[:,1]\n",
    "    ypred = (p1 > t)*1\n",
    "    return ypred\n",
    "\n",
    "#your code here: look at other thresholds for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making ROC curves for this model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def make_roc(name, clf, ytest, xtest, ax=None, labe=5, proba=True, skip=0):\n",
    "    initial=False\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "        initial=True\n",
    "    if proba:#for stuff like logistic regression\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n",
    "    else:#for stuff like SVM\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if skip:\n",
    "        l=fpr.shape[0]\n",
    "        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    else:\n",
    "        ax.plot(fpr, tpr, '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    label_kwargs = {}\n",
    "    label_kwargs['bbox'] = dict(\n",
    "        boxstyle='round,pad=0.3', alpha=0.2,\n",
    "    )\n",
    "    if labe!=None:\n",
    "        for k in range(0, fpr.shape[0],labe):\n",
    "            #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n",
    "            threshold = str(np.round(thresholds[k], 2))\n",
    "            ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n",
    "    if initial:\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return ax\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "ax=make_roc(\"logistic\",logit, y_test, X_test, labe=10, skip=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get back the data with missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first build a model to impute using data without missing \n",
    "plt.hist(gssdata_full['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#back to the data set with missingness and impute the mean\n",
    "gssdata2 = gssdata.copy()\n",
    "gssdata2['income'] = gssdata['income'].fillna(gssdata_full['income'].mean())\n",
    "plt.hist(gssdata2['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "itrain, itest = train_test_split(range(gssdata2.shape[0]), train_size=0.50)\n",
    "#gsstemp = gssdata_full.drop(['health','fairhealth','goodhealth','excellenthealth','sex','sexornt','partyid','race'],axis=1)\n",
    "gsstemp = gssdata2[['age','educ','female','partyid_dem','partyid_rep','income']]\n",
    "X_train2 = gsstemp.iloc[itrain, :]\n",
    "X_test2 = gsstemp.iloc[itest, :]\n",
    "y_train2 = gssdata2['poorhealth'].iloc[itrain]\n",
    "y_test2 = gssdata2['poorhealth'].iloc[itest]\n",
    "\n",
    "y_train.shape, X_train.shape, y_test.shape, X_test.shape\n",
    "\n",
    "logit2 = LogisticRegression(C=1000000)\n",
    "logit2.fit(X_train2, y_train2) \n",
    "print(logit2.score(X_test2,y_test2))\n",
    "logit2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here: create confusion table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here: create an ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation with a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the dataset without NAs to build a model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "gssdata_full.head()\n",
    "\n",
    "X_imp = gssdata_full[['age','educ','female','partyid_dem','partyid_rep']]\n",
    "y_imp = gssdata_full['income']\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regress = LinearRegression()\n",
    "regress.fit(X_imp,y_imp)\n",
    "y_hat = regress.predict(X_imp)\n",
    "\n",
    "#your code here: do the imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_index = gssdata.income[gssdata.income.isnull()].index\n",
    "missing_series = pd.Series(data = y_missing_noise, index = missing_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#back to the data set with missingness and impute the predictions\n",
    "gssdata_imp = gssdata.copy()\n",
    "\n",
    "gssdata_imp['income'] = gssdata_imp['income'].fillna(missing_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gssdata_imp['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsstemp = gssdata_imp[['age','educ','female','partyid_dem','partyid_rep','income']]\n",
    "X_train3 = gsstemp.iloc[itrain, :]\n",
    "X_test3 = gsstemp.iloc[itest, :]\n",
    "#y_train3 = gssdata_imp['poorhealth'].iloc[itrain]\n",
    "#y_test3 = gssdata_imp['poorhealth'].iloc[itest]\n",
    "\n",
    "y_train.shape, X_train.shape, y_test.shape, X_test.shape\n",
    "\n",
    "logit3 = LogisticRegression(C=1000000)\n",
    "logit3.fit(X_train3, y_train2) \n",
    "print(logit3.score(X_test3,y_test2))\n",
    "logit3.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test2,t_repredict(logit3, 0.5, X_test3)))\n",
    "print(confusion_matrix(y_train2,t_repredict(logit3, 0.5, X_train3)))\n",
    "\n",
    "print(confusion_matrix(y_test2,t_repredict(logit3, 0.1, X_test3)))\n",
    "print(confusion_matrix(y_train2,t_repredict(logit3, 0.1, X_train3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"poster\")\n",
    "ax=make_roc(\"logistic\",logit3, y_test2, X_test3, labe=10, skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
